{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdd8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math_helper_functions import log_stable\n",
    "from math_helper_functions import softmax\n",
    "from math_helper_functions import kl_div\n",
    "import numpy as np\n",
    "import math\n",
    "from pymdp.maths import spm_log_single as log_stable\n",
    "\n",
    "EPS_VAL = 1e-16 #negligibleconstant\n",
    "\n",
    "def entropy(A):\n",
    "    \"\"\" Compute the entropy of a set of condition distributions, i.e. one entropy value per column \"\"\"\n",
    "    \n",
    "    H_A = - (A * log_stable(A)).sum(axis=0)\n",
    "    return H_A\n",
    "\n",
    "#Dynamic programming in G (expected free energy)\n",
    "\n",
    "def action_dist(A, B, C, T, sm_par):\n",
    "    \n",
    "    num_modalities = A.shape[0]\n",
    "    num_factors = B.shape[0]\n",
    "\n",
    "    num_states = []\n",
    "    for i in range(num_factors):\n",
    "        num_states.append(B[i].shape[0])\n",
    "\n",
    "    num_obs = []\n",
    "    for i in range(num_modalities):\n",
    "        num_obs.append(A[i].shape[0])\n",
    "\n",
    "    num_controls = []\n",
    "    for i in range(num_factors):\n",
    "        num_controls.append(B[i].shape[2])\n",
    "\n",
    "    numS = 1\n",
    "    for i in num_states:\n",
    "        numS *= i\n",
    "    numA = 1\n",
    "    for i in num_controls:\n",
    "        numA *= i\n",
    "\n",
    "    new_num_states = [numS]\n",
    "    new_num_controls = [numA]\n",
    "\n",
    "    new_A = utils.random_A_matrix(num_obs, new_num_states) #* 0 + EPS_VAL\n",
    "    new_B = utils.random_B_matrix(1, 1) #* 0 + EPS_VAL\n",
    "\n",
    "    for i in range(num_modalities):\n",
    "        new_A[i] = np.reshape(A[i], [A[i].shape[0], numS])\n",
    "\n",
    "    for i in range(num_factors):\n",
    "        new_B[0] = np.kron(new_B[0],B[i])\n",
    "\n",
    "    #Expected free energy (Only RISK)\n",
    "    \n",
    "    G = np.zeros((T-1, numA, numS))\n",
    "    Q_actions = np.zeros((T-1, numA, numS))\n",
    "\n",
    "    for mod in range(num_modalities):\n",
    "\n",
    "        Q_po = np.zeros((A[mod].shape[0], numS, numA))\n",
    "\n",
    "        for i in range(numS):\n",
    "            for j in range(numA):\n",
    "                Q_po[:,i,j] = new_A[mod].dot(new_B[0][:,i,j])\n",
    "\n",
    "        for k in range(T-2,-1,-1):\n",
    "            for i in range(numA):\n",
    "                for j in range(numS):\n",
    "\n",
    "                    if(k==T-2):\n",
    "                        G[k,i,j] += kl_div(Q_po[:,j,i],C[mod])\n",
    "\n",
    "                    else:\n",
    "                        G[k,i,j] += kl_div(Q_po[:,j,i],C[mod])\n",
    "                        for jj in range(numS):\n",
    "                            for kk in range(numA):\n",
    "                                G[k,i,j] += Q_actions[k+1,kk,jj]*new_B[0][jj,j,i]*G[k+1,kk,jj]\n",
    "\n",
    "            #Distribution for action-selection\n",
    "            for ppp in range(numS):\n",
    "                Q_actions[k,:,ppp] = softmax(sm_par*(-1*G[k,:,ppp]))\n",
    "                \n",
    "    return Q_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b5653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Hidden)Factors\n",
    "s1_size = 42\n",
    "\n",
    "num_states = [s1_size]\n",
    "num_factors = len(num_states)\n",
    "\n",
    "# Rewards\n",
    "reward_modes = 3 #Max score-5 (assumption)\n",
    "\n",
    "# Controls\n",
    "s1_actions = ['Stay', 'Play-Up', 'Play-Down']\n",
    "num_controls = [len(s1_actions)]\n",
    "\n",
    "# Observations\n",
    "#Ball-x\n",
    "o1_obs_size = s1_size\n",
    "#Ball-y\n",
    "o2_obs_size = s1_size\n",
    "#Ball-vx\n",
    "o3_obs_size = 2\n",
    "#Ball-vy\n",
    "o4_obs_size = 2\n",
    "#Paddle-pos\n",
    "o5_obs_size = s1_size\n",
    "#Paddle-velocity\n",
    "o6_obs_size = 2\n",
    "#Reward (Shock, Chocolate, and Nothing)\n",
    "reward_obs_size = reward_modes\n",
    "\n",
    "num_obs = [o1_obs_size, o2_obs_size, o3_obs_size, o4_obs_size, o5_obs_size, o6_obs_size, reward_obs_size]\n",
    "num_modalities = len(num_obs)\n",
    "\n",
    "EPS_VAL = 1e-16 # Negligibleconstant\n",
    "\n",
    "# Likelhiood Dynamics\n",
    "A = utils.random_A_matrix(num_obs, num_states)*0 + EPS_VAL\n",
    "\n",
    "# Transisition dynamics\n",
    "# Initialised as random becuase the agent need to learn the dynamics\n",
    "\n",
    "B = utils.random_B_matrix(num_states, num_controls)*0 + EPS_VAL\n",
    "\n",
    "numS = 1\n",
    "for i in num_states:\n",
    "    numS *= i\n",
    "numA = 1\n",
    "for i in num_controls:\n",
    "    numA *= i\n",
    "\n",
    "A = normalise_A(A, num_states, num_modalities)\n",
    "B = normalise_B(B, num_states, num_controls)\n",
    "\n",
    "# Prior preferences for biasing the generative model to control behaviour\n",
    "\n",
    "# The preferences are set uniform for all the hidden-states except the reward function\n",
    "C = utils.obj_array_uniform(num_obs)\n",
    "\n",
    "# Highest for the high-score and lowest for the lowscore\n",
    "C_score = np.array([-5.8, 0 , 1])\n",
    "# Normalising the prior preference\n",
    "C[6] = pymdp.maths.softmax(1*C_score)\n",
    "\n",
    "#Prior over hidden-states\n",
    "D = utils.obj_array_uniform(num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f73bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp import utils\n",
    "import pymdp\n",
    "from math_helper_functions import normalise_A, normalise_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723f4268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 356 ms\n"
     ]
    }
   ],
   "source": [
    "%time Q_pi = action_dist(A, B, C, T=5, sm_par=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c68140",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=5\n",
    "sm_par=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab00b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modalities = A.shape[0]\n",
    "num_factors = B.shape[0]\n",
    "\n",
    "num_states = []\n",
    "for i in range(num_factors):\n",
    "    num_states.append(B[i].shape[0])\n",
    "\n",
    "num_obs = []\n",
    "for i in range(num_modalities):\n",
    "    num_obs.append(A[i].shape[0])\n",
    "\n",
    "num_controls = []\n",
    "for i in range(num_factors):\n",
    "    num_controls.append(B[i].shape[2])\n",
    "\n",
    "numS = 1\n",
    "for i in num_states:\n",
    "    numS *= i\n",
    "numA = 1\n",
    "for i in num_controls:\n",
    "    numA *= i\n",
    "\n",
    "new_num_states = [numS]\n",
    "new_num_controls = [numA]\n",
    "\n",
    "new_A = utils.random_A_matrix(num_obs, new_num_states) #* 0 + EPS_VAL\n",
    "new_B = utils.random_B_matrix(1, 1) #* 0 + EPS_VAL\n",
    "\n",
    "for i in range(num_modalities):\n",
    "    new_A[i] = np.reshape(A[i], [A[i].shape[0], numS])\n",
    "\n",
    "for i in range(num_factors):\n",
    "    new_B[0] = np.kron(new_B[0],B[i])\n",
    "\n",
    "#Expected free energy (Only RISK)\n",
    "\n",
    "G = np.zeros((T-1, numA, numS))\n",
    "Q_actions = np.zeros((T-1, numA, numS))\n",
    "\n",
    "for mod in range(num_modalities):\n",
    "\n",
    "    Q_po = np.zeros((A[mod].shape[0], numS, numA))\n",
    "\n",
    "    for i in range(numS):\n",
    "        for j in range(numA):\n",
    "            Q_po[:,i,j] = new_A[mod].dot(new_B[0][:,i,j])\n",
    "\n",
    "    for k in range(T-2,-1,-1):\n",
    "        for i in range(numA):\n",
    "            for j in range(numS):\n",
    "\n",
    "                if(k==T-2):\n",
    "                    G[k,i,j] += kl_div(Q_po[:,j,i],C[mod]) + np.dot(new_B[0][:,j,i],entropy(new_A[0]))\n",
    "\n",
    "                else:\n",
    "                    G[k,i,j] += kl_div(Q_po[:,j,i],C[mod]) + np.dot(new_B[0][:,j,i],entropy(new_A[0]))\n",
    "                    for jj in range(numS):\n",
    "                        for kk in range(numA):\n",
    "                            G[k,i,j] += Q_actions[k+1,kk,jj]*new_B[0][jj,j,i]*G[k+1,kk,jj]\n",
    "\n",
    "        #Distribution for action-selection\n",
    "        for ppp in range(numS):\n",
    "            Q_actions[k,:,ppp] = softmax(sm_par*(-1*G[k,:,ppp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47e3a8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.737669618283361"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(new_B[0][:,0,0],entropy(new_A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626904b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5469b8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(new_A[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d32f3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 42, 3), (42, 42))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_B[0].shape, new_A[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7628bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_actions[0,:,:]*(new_B[0][:,:,0].dot(entropy(new_A[0])))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff6e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
